{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Importing package and data\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "df = pd.read_csv('unlabeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                             review  \\\n",
      "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...   \n",
      "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...   \n",
      "\n",
      "                                        clean_review  \n",
      "0  watching time chasers it obvious that it was m...  \n",
      "1  saw this film about years ago and remember it ...  \n"
     ]
    }
   ],
   "source": [
    "#Cleaning the string\n",
    "\n",
    "def clean_str(string):\n",
    "  \"\"\"\n",
    "  String cleaning before vectorization\n",
    "  \"\"\"\n",
    "  try:\n",
    "    #string = \"\".join(string.astype('str').tail(1).tolist())    \n",
    "    string = re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*', '', string, flags=re.MULTILINE)\n",
    "    string = re.sub(r\"[^A-Za-z]\", \" \", string)         \n",
    "    words = string.strip().lower().split()    \n",
    "    words = [w for w in words if len(w)>1]\n",
    "    return \" \".join(words)\t\n",
    "  except:\n",
    "    return \"\"\n",
    "\n",
    "df['clean_review'] = df['review'].apply(clean_str)\n",
    "print (df[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create list of words for each document for feeding to Word2Vec\n",
    "documents = []\n",
    "for doc in df['clean_review']:\n",
    "    documents.append(doc.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-07 10:50:08,227 : INFO : collecting all words and their counts\n",
      "2017-08-07 10:50:08,227 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-07 10:50:08,579 : INFO : PROGRESS: at sentence #10000, processed 2253398 words, keeping 51628 word types\n",
      "2017-08-07 10:50:08,949 : INFO : PROGRESS: at sentence #20000, processed 4540660 words, keeping 69051 word types\n",
      "2017-08-07 10:50:09,318 : INFO : PROGRESS: at sentence #30000, processed 6825039 words, keeping 81489 word types\n",
      "2017-08-07 10:50:09,671 : INFO : PROGRESS: at sentence #40000, processed 9080729 words, keeping 91659 word types\n",
      "2017-08-07 10:50:10,024 : INFO : collected 100453 word types from a corpus of 11348950 raw words and 50000 sentences\n",
      "2017-08-07 10:50:10,040 : INFO : Loading a fresh vocabulary\n",
      "2017-08-07 10:50:10,358 : INFO : min_count=10 retains 28296 unique words (28% of original 100453, drops 72157)\n",
      "2017-08-07 10:50:10,358 : INFO : min_count=10 leaves 11174747 word corpus (98% of original 11348950, drops 174203)\n",
      "2017-08-07 10:50:10,445 : INFO : deleting the raw counts dictionary of 100453 items\n",
      "2017-08-07 10:50:10,450 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2017-08-07 10:50:10,450 : INFO : downsampling leaves estimated 8479794 word corpus (75.9% of prior 11174747)\n",
      "2017-08-07 10:50:10,450 : INFO : estimated required memory for 28296 words and 300 dimensions: 82058400 bytes\n",
      "2017-08-07 10:50:10,521 : INFO : resetting layer weights\n",
      "2017-08-07 10:50:10,914 : INFO : training model with 4 workers on 28296 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-07 10:50:11,915 : INFO : PROGRESS: at 1.49% examples, 1248167 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:12,914 : INFO : PROGRESS: at 2.98% examples, 1255816 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:13,923 : INFO : PROGRESS: at 4.46% examples, 1257449 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:14,927 : INFO : PROGRESS: at 5.95% examples, 1260281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:15,922 : INFO : PROGRESS: at 7.46% examples, 1263809 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:16,932 : INFO : PROGRESS: at 8.94% examples, 1257679 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:17,932 : INFO : PROGRESS: at 10.39% examples, 1255645 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:18,945 : INFO : PROGRESS: at 11.85% examples, 1248820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:19,952 : INFO : PROGRESS: at 13.34% examples, 1249509 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:20,956 : INFO : PROGRESS: at 14.83% examples, 1252215 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:21,970 : INFO : PROGRESS: at 16.31% examples, 1253111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:22,971 : INFO : PROGRESS: at 17.83% examples, 1254968 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:23,964 : INFO : PROGRESS: at 19.33% examples, 1255294 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:24,962 : INFO : PROGRESS: at 20.84% examples, 1256672 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:25,979 : INFO : PROGRESS: at 22.36% examples, 1257785 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:26,979 : INFO : PROGRESS: at 23.85% examples, 1258884 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:27,975 : INFO : PROGRESS: at 25.32% examples, 1258259 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:28,982 : INFO : PROGRESS: at 26.81% examples, 1258884 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:29,979 : INFO : PROGRESS: at 28.32% examples, 1259161 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:30,992 : INFO : PROGRESS: at 29.82% examples, 1259550 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:31,980 : INFO : PROGRESS: at 31.32% examples, 1259762 words/s, in_qsize 6, out_qsize 1\n",
      "2017-08-07 10:50:33,001 : INFO : PROGRESS: at 32.82% examples, 1259416 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:34,012 : INFO : PROGRESS: at 34.30% examples, 1259415 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:35,012 : INFO : PROGRESS: at 35.77% examples, 1259158 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:36,007 : INFO : PROGRESS: at 37.28% examples, 1259808 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:37,019 : INFO : PROGRESS: at 38.79% examples, 1260201 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:38,027 : INFO : PROGRESS: at 40.30% examples, 1260718 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:39,020 : INFO : PROGRESS: at 41.81% examples, 1260813 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:40,031 : INFO : PROGRESS: at 43.28% examples, 1260173 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:41,023 : INFO : PROGRESS: at 44.76% examples, 1260498 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:42,030 : INFO : PROGRESS: at 46.22% examples, 1260124 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:43,031 : INFO : PROGRESS: at 47.72% examples, 1260248 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:44,038 : INFO : PROGRESS: at 49.23% examples, 1260486 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:45,040 : INFO : PROGRESS: at 50.72% examples, 1260040 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:46,047 : INFO : PROGRESS: at 52.24% examples, 1260506 words/s, in_qsize 6, out_qsize 0\n",
      "2017-08-07 10:50:47,048 : INFO : PROGRESS: at 53.69% examples, 1259677 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:48,052 : INFO : PROGRESS: at 55.14% examples, 1258963 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:49,075 : INFO : PROGRESS: at 56.56% examples, 1257268 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:50:50,065 : INFO : PROGRESS: at 57.95% examples, 1254865 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:51,072 : INFO : PROGRESS: at 59.41% examples, 1254422 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:52,084 : INFO : PROGRESS: at 60.89% examples, 1254169 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:53,080 : INFO : PROGRESS: at 62.39% examples, 1254167 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:54,084 : INFO : PROGRESS: at 63.79% examples, 1252701 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:55,084 : INFO : PROGRESS: at 65.27% examples, 1252767 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:56,097 : INFO : PROGRESS: at 66.69% examples, 1251912 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:57,097 : INFO : PROGRESS: at 68.20% examples, 1252078 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:58,097 : INFO : PROGRESS: at 69.67% examples, 1252096 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:50:59,111 : INFO : PROGRESS: at 71.11% examples, 1250949 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:00,121 : INFO : PROGRESS: at 72.53% examples, 1249845 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:01,121 : INFO : PROGRESS: at 73.97% examples, 1249372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:02,125 : INFO : PROGRESS: at 75.42% examples, 1249035 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:03,123 : INFO : PROGRESS: at 76.86% examples, 1248607 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:04,119 : INFO : PROGRESS: at 78.30% examples, 1247872 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:05,134 : INFO : PROGRESS: at 79.74% examples, 1247379 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:51:06,134 : INFO : PROGRESS: at 81.18% examples, 1246497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:07,135 : INFO : PROGRESS: at 82.67% examples, 1246481 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:08,136 : INFO : PROGRESS: at 84.15% examples, 1246845 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:51:09,152 : INFO : PROGRESS: at 85.65% examples, 1247159 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:10,152 : INFO : PROGRESS: at 87.17% examples, 1247862 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:11,152 : INFO : PROGRESS: at 88.66% examples, 1247911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:12,167 : INFO : PROGRESS: at 90.20% examples, 1248575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:13,183 : INFO : PROGRESS: at 91.71% examples, 1248721 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:14,183 : INFO : PROGRESS: at 93.20% examples, 1248941 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:15,183 : INFO : PROGRESS: at 94.69% examples, 1249255 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-07 10:51:16,199 : INFO : PROGRESS: at 96.16% examples, 1249286 words/s, in_qsize 8, out_qsize 0\n",
      "2017-08-07 10:51:17,199 : INFO : PROGRESS: at 97.66% examples, 1249544 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:18,214 : INFO : PROGRESS: at 99.19% examples, 1249776 words/s, in_qsize 7, out_qsize 0\n",
      "2017-08-07 10:51:18,730 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-08-07 10:51:18,730 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-07 10:51:18,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-07 10:51:18,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-07 10:51:18,746 : INFO : training on 113489500 raw words (84801167 effective words) took 67.8s, 1250133 effective words/s\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "w2v_movie_review = gensim.models.Word2Vec(documents, min_count=10, sample=1e-3,workers=4,size=300,window=5,iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28296, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many words in the model and how many features\n",
    "w2v_movie_review.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-07 11:25:23,013 : INFO : saving Word2Vec object under /tmp/w2v-movie-review, separately None\n",
      "2017-08-07 11:25:23,014 : INFO : not storing attribute syn0norm\n",
      "2017-08-07 11:25:23,015 : INFO : not storing attribute cum_table\n",
      "2017-08-07 11:25:23,774 : INFO : saved /tmp/w2v-movie-review\n"
     ]
    }
   ],
   "source": [
    "w2v_movie_review.save('/tmp/w2v-movie-review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1dbe191f7f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_movie_review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
